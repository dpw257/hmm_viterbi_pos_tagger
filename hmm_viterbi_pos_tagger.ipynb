{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TO RUN THIS POS TAGGER, PLACE YOUR TAGGED CORPUS IN THE SAME FOLDER AS THE JUPYTER NOTEBOOK.\n",
    "THE TAGGED CORPUS MUST BE A CSV FILE. SAVE TWO COPIES OF THE CORPUS RENAMED AS FOLLOWS:\n",
    "* trainingset_transmissions.csv\n",
    "* trainingset_emissions.csv\n",
    "DATA MUST BE SAVED IN THE FOLLOWING FORMAT:\n",
    "<START>_START,token_tag,token_tag,token_tag,token_tag,<END>_END\n",
    "(OPTIONAL: Lists of additional tagged tokens may be added to the emission dataset to avoid zero-probabilities of common words, such as verbs or numbers)\n",
    "\n",
    "PLACE YOUR UNTAGGED TEXT IN THE SAME FOLDER AS THE JUPYTER NOTEBOOK.\n",
    "RENAME THE FILE AS FOLLOWS:\n",
    "* testset.csv\n",
    "DATA MUST BE SAVED IN THE FOLLOWING FORMAT:\n",
    "<START>,token,token,token,token,<END>\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN CSV FILE FOR TRANSMISSION PROBABILITIES\n",
    "\n",
    "import pandas\n",
    "df1 = pandas.read_csv('trainingset_transmissions.csv')\n",
    "single_str_list = df1.values.tolist()\n",
    "\n",
    "\n",
    "# Convert the training set into tuples of tokens and tags\n",
    "table = []\n",
    "for sent in single_str_list:\n",
    "    table.append(sent[1:])\n",
    "\n",
    "\n",
    "#Split tags back into list of lists (sentences) of tuples:\n",
    "tuple_list = []\n",
    "for sent in table:\n",
    "    new_sent = []\n",
    "    for tag_pair in sent:\n",
    "        if isinstance(tag_pair, str):\n",
    "            for i in range(len(tag_pair)):\n",
    "                if tag_pair[i] == '_':\n",
    "                    new_sent.append((tag_pair[:i], tag_pair[i+1:]))\n",
    "    tuple_list.append(new_sent)\n",
    "\n",
    "print(tuple_list[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                START       cop       adj       det      noun      conj  \\\n",
      "START             0.0  0.115111  0.008222  0.021556  0.075778  0.082000   \n",
      "cop               0.0  0.002277  0.362550  0.006261  0.296528  0.006261   \n",
      "adj               0.0  0.011309  0.075929  0.031018  0.106300  0.043134   \n",
      "det               0.0  0.001497  0.020767  0.000000  0.811225  0.000000   \n",
      "noun              0.0  0.012734  0.106880  0.057507  0.133292  0.041939   \n",
      "conj              0.0  0.059587  0.019068  0.071504  0.244439  0.007680   \n",
      "prep              0.0  0.003730  0.017144  0.095645  0.454945  0.013174   \n",
      "prop              0.0  0.006091  0.023256  0.020044  0.044186  0.056035   \n",
      "dem               0.0  0.017525  0.063197  0.025491  0.105682  0.053107   \n",
      "pun               0.0  0.020294  0.012850  0.017281  0.081531  0.068327   \n",
      "vb.pasthab.aut    0.0  0.000000  0.200000  0.150000  0.050000  0.050000   \n",
      "obj               0.0  0.018487  0.052101  0.136975  0.077311  0.043697   \n",
      "par               0.0  0.000363  0.176940  0.000725  0.151922  0.000000   \n",
      "neg               0.0  0.000000  0.013652  0.000000  0.228669  0.010239   \n",
      "vb.ord            0.0  0.021352  0.017794  0.078292  0.120996  0.039146   \n",
      "END               0.0  0.000000  0.214286  0.000000  0.000000  0.000000   \n",
      "num               0.0  0.004781  0.015936  0.003984  0.306773  0.043825   \n",
      "vb.past           0.0  0.006874  0.020218  0.113223  0.148403  0.005257   \n",
      "rel               0.0  0.000574  0.004020  0.000000  0.000000  0.000000   \n",
      "vn                0.0  0.006180  0.055618  0.025281  0.083427  0.033146   \n",
      "adv               0.0  0.012469  0.077307  0.014963  0.147548  0.039900   \n",
      "vb.pasthab        0.0  0.004049  0.012146  0.109312  0.153846  0.028340   \n",
      "pos               0.0  0.000000  0.008072  0.000000  0.863677  0.000000   \n",
      "comp              0.0  0.002432  0.000608  0.000000  0.168997  0.000608   \n",
      "vb.ord.syn        0.0  0.003861  0.038610  0.046332  0.065637  0.019305   \n",
      "qual              0.0  0.005391  0.010782  0.000000  0.695418  0.002695   \n",
      "vb.past.aut       0.0  0.000000  0.015094  0.120755  0.143396  0.018868   \n",
      "vb.con            0.0  0.014599  0.021898  0.111314  0.240876  0.001825   \n",
      "sub               0.0  0.008712  0.102614  0.040658  0.139400  0.021781   \n",
      "vb.past.syn       0.0  0.009524  0.038095  0.038095  0.200000  0.028571   \n",
      "vb.pres           0.0  0.007928  0.038128  0.124953  0.212156  0.009060   \n",
      "sconj             0.0  0.031873  0.034861  0.004980  0.061753  0.001992   \n",
      "vb.sub            0.0  0.001980  0.035644  0.126733  0.247525  0.011881   \n",
      "eng               0.0  0.002538  0.005076  0.000000  0.162437  0.005076   \n",
      "q                 0.0  0.107759  0.000000  0.004310  0.280172  0.030172   \n",
      "sym               0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pres.syn       0.0  0.028777  0.100719  0.028777  0.064748  0.014388   \n",
      "vb.fut            0.0  0.024735  0.003534  0.141343  0.169611  0.003534   \n",
      "vb.con.aut        0.0  0.000000  0.000000  0.075000  0.216667  0.000000   \n",
      "vb.ord.aut        0.0  0.011236  0.022472  0.157303  0.258427  0.011236   \n",
      "vb.fut.aut        0.0  0.000000  0.025000  0.100000  0.237500  0.012500   \n",
      "vb.sub.aut        0.0  0.029126  0.029126  0.097087  0.116505  0.019417   \n",
      "vb.con.syn        0.0  0.021053  0.105263  0.084211  0.105263  0.010526   \n",
      "vb.pasthab.syn    0.0  0.000000  0.130435  0.021739  0.108696  0.152174   \n",
      "int               0.0  0.000000  0.021739  0.000000  0.239130  0.000000   \n",
      "voc               0.0  0.000000  0.111111  0.000000  0.444444  0.000000   \n",
      "vb.pres.spec      0.0  0.200000  0.000000  0.200000  0.100000  0.000000   \n",
      "vb.fut.spec       0.0  0.000000  0.047619  0.047619  0.095238  0.000000   \n",
      "vb.preshab        0.0  0.005376  0.021505  0.123656  0.279570  0.005376   \n",
      "abbr              0.0  0.000000  0.000000  0.000000  0.045455  0.030303   \n",
      "vb.inf            0.0  0.000000  0.055556  0.055556  0.166667  0.000000   \n",
      "vb.fut.syn        0.0  0.000000  0.111111  0.111111  0.111111  0.000000   \n",
      "vb.pres.aut       0.0  0.000000  0.009901  0.128713  0.138614  0.029703   \n",
      "vb.preshab.aut    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "for               0.0  0.090909  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.preshab.syn    0.0  0.000000  0.250000  0.000000  0.000000  0.000000   \n",
      "vb.sub.syn        0.0  0.050000  0.000000  0.200000  0.100000  0.050000   \n",
      "vb.past.spec      0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "                    prep      prop       dem       pun  ...  vb.preshab  \\\n",
      "START           0.092889  0.025333  0.009778  0.046889  ...    0.004667   \n",
      "cop             0.056346  0.007968  0.006830  0.011952  ...    0.000000   \n",
      "adj             0.291115  0.017124  0.020517  0.185784  ...    0.000162   \n",
      "det             0.007484  0.116558  0.000000  0.000748  ...    0.000187   \n",
      "noun            0.210433  0.049949  0.037872  0.137277  ...    0.000123   \n",
      "conj            0.127648  0.015360  0.017479  0.015360  ...    0.003178   \n",
      "prep            0.059853  0.081268  0.014016  0.057026  ...    0.000301   \n",
      "prop            0.142636  0.287154  0.008195  0.244518  ...    0.000000   \n",
      "dem             0.181094  0.032926  0.002655  0.268189  ...    0.000000   \n",
      "pun             0.076037  0.050160  0.003545  0.053616  ...    0.002038   \n",
      "vb.pasthab.aut  0.200000  0.000000  0.000000  0.000000  ...    0.000000   \n",
      "obj             0.136134  0.047059  0.087395  0.175630  ...    0.000000   \n",
      "par             0.003626  0.493474  0.001450  0.014503  ...    0.000725   \n",
      "neg             0.046075  0.052901  0.000000  0.005119  ...    0.023891   \n",
      "vb.ord          0.263345  0.056940  0.021352  0.049822  ...    0.000000   \n",
      "END             0.142857  0.214286  0.071429  0.142857  ...    0.000000   \n",
      "num             0.095618  0.028685  0.004781  0.312351  ...    0.000000   \n",
      "vb.past         0.156894  0.088556  0.008896  0.025071  ...    0.000000   \n",
      "rel             0.000574  0.000861  0.000000  0.000287  ...    0.016652   \n",
      "vn              0.464326  0.007584  0.013483  0.120506  ...    0.000000   \n",
      "adv             0.283458  0.009559  0.009144  0.210723  ...    0.000831   \n",
      "vb.pasthab      0.251012  0.048583  0.004049  0.080972  ...    0.000000   \n",
      "pos             0.004484  0.017040  0.002691  0.026906  ...    0.000000   \n",
      "comp            0.021277  0.005471  0.000608  0.004255  ...    0.016413   \n",
      "vb.ord.syn      0.548263  0.023166  0.007722  0.069498  ...    0.000000   \n",
      "qual            0.061995  0.026954  0.013477  0.053908  ...    0.000000   \n",
      "vb.past.aut     0.252830  0.079245  0.000000  0.011321  ...    0.000000   \n",
      "vb.con          0.133212  0.038321  0.016423  0.021898  ...    0.000000   \n",
      "sub             0.373185  0.021297  0.024685  0.077444  ...    0.000000   \n",
      "vb.past.syn     0.361905  0.000000  0.019048  0.095238  ...    0.000000   \n",
      "vb.pres         0.161193  0.058890  0.007173  0.021895  ...    0.000000   \n",
      "sconj           0.005976  0.133466  0.034861  0.041833  ...    0.016932   \n",
      "vb.sub          0.089109  0.035644  0.007921  0.025743  ...    0.000000   \n",
      "eng             0.027919  0.152284  0.000000  0.109137  ...    0.000000   \n",
      "q               0.043103  0.008621  0.004310  0.017241  ...    0.000000   \n",
      "sym             0.129412  0.000000  0.000000  0.141176  ...    0.000000   \n",
      "vb.pres.syn     0.374101  0.007194  0.000000  0.043165  ...    0.000000   \n",
      "vb.fut          0.106007  0.028269  0.000000  0.017668  ...    0.000000   \n",
      "vb.con.aut      0.241667  0.075000  0.008333  0.058333  ...    0.000000   \n",
      "vb.ord.aut      0.247191  0.011236  0.022472  0.044944  ...    0.000000   \n",
      "vb.fut.aut      0.200000  0.012500  0.012500  0.012500  ...    0.000000   \n",
      "vb.sub.aut      0.262136  0.019417  0.019417  0.067961  ...    0.000000   \n",
      "vb.con.syn      0.263158  0.000000  0.010526  0.126316  ...    0.000000   \n",
      "vb.pasthab.syn  0.195652  0.065217  0.021739  0.108696  ...    0.000000   \n",
      "int             0.065217  0.108696  0.065217  0.217391  ...    0.000000   \n",
      "voc             0.000000  0.222222  0.000000  0.222222  ...    0.000000   \n",
      "vb.pres.spec    0.000000  0.000000  0.000000  0.000000  ...    0.000000   \n",
      "vb.fut.spec     0.428571  0.000000  0.000000  0.000000  ...    0.000000   \n",
      "vb.preshab      0.225806  0.005376  0.005376  0.021505  ...    0.000000   \n",
      "abbr            0.015152  0.090909  0.000000  0.727273  ...    0.000000   \n",
      "vb.inf          0.388889  0.000000  0.000000  0.222222  ...    0.000000   \n",
      "vb.fut.syn      0.222222  0.000000  0.000000  0.000000  ...    0.000000   \n",
      "vb.pres.aut     0.405941  0.000000  0.009901  0.019802  ...    0.000000   \n",
      "vb.preshab.aut  1.000000  0.000000  0.000000  0.000000  ...    0.000000   \n",
      "for             0.454545  0.090909  0.000000  0.272727  ...    0.000000   \n",
      "vb.preshab.syn  0.500000  0.000000  0.000000  0.250000  ...    0.000000   \n",
      "vb.sub.syn      0.250000  0.000000  0.050000  0.000000  ...    0.000000   \n",
      "vb.past.spec    0.000000  0.000000  0.000000  0.000000  ...    0.000000   \n",
      "\n",
      "                    abbr    vb.inf  vb.fut.syn  vb.pres.aut  vb.preshab.aut  \\\n",
      "START           0.000222  0.000667    0.000444     0.006222        0.000000   \n",
      "cop             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "adj             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "det             0.000561  0.000187    0.000000     0.000000        0.000000   \n",
      "noun            0.000329  0.000246    0.000041     0.000205        0.000000   \n",
      "conj            0.000265  0.000000    0.000265     0.001589        0.000000   \n",
      "prep            0.000180  0.000000    0.000000     0.000000        0.000000   \n",
      "prop            0.000443  0.000000    0.000000     0.000000        0.000000   \n",
      "dem             0.002655  0.000000    0.000000     0.002124        0.000000   \n",
      "pun             0.002924  0.000354    0.000089     0.000886        0.000000   \n",
      "vb.pasthab.aut  0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "obj             0.000000  0.000000    0.000840     0.000000        0.000000   \n",
      "par             0.000000  0.000000    0.000363     0.000725        0.000000   \n",
      "neg             0.000000  0.000000    0.000000     0.010239        0.000000   \n",
      "vb.ord          0.000000  0.000000    0.000000     0.003559        0.000000   \n",
      "END             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "num             0.002390  0.000000    0.000000     0.001594        0.000000   \n",
      "vb.past         0.000000  0.000000    0.000000     0.000404        0.000000   \n",
      "rel             0.000000  0.000287    0.000574     0.006604        0.000000   \n",
      "vn              0.000000  0.000281    0.000000     0.000000        0.000000   \n",
      "adv             0.000000  0.000831    0.000000     0.001247        0.000000   \n",
      "vb.pasthab      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "pos             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "comp            0.000000  0.000000    0.000000     0.001824        0.000000   \n",
      "vb.ord.syn      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "qual            0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.past.aut     0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.con          0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "sub             0.000484  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.past.syn     0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.pres         0.000378  0.000000    0.000000     0.000000        0.000000   \n",
      "sconj           0.000000  0.000000    0.000000     0.006972        0.000996   \n",
      "vb.sub          0.001980  0.000000    0.000000     0.000000        0.000000   \n",
      "eng             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "q               0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "sym             0.011765  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.pres.syn     0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.fut          0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.con.aut      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.ord.aut      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.fut.aut      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.sub.aut      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.con.syn      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.pasthab.syn  0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "int             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "voc             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.pres.spec    0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.fut.spec     0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.preshab      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "abbr            0.015152  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.inf          0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.fut.syn      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.pres.aut     0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.preshab.aut  0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "for             0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.preshab.syn  0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.sub.syn      0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "vb.past.spec    0.000000  0.000000    0.000000     0.000000        0.000000   \n",
      "\n",
      "                     for  vb.preshab.syn  vb.sub.syn  vb.past.spec  \n",
      "START           0.000000        0.000000    0.000444      0.000000  \n",
      "cop             0.000000        0.000000    0.000000      0.000000  \n",
      "adj             0.000000        0.000162    0.000000      0.000000  \n",
      "det             0.000000        0.000000    0.000000      0.000000  \n",
      "noun            0.000164        0.000000    0.000000      0.000000  \n",
      "conj            0.000000        0.000000    0.000530      0.000000  \n",
      "prep            0.000060        0.000000    0.000060      0.000000  \n",
      "prop            0.000221        0.000000    0.000000      0.000000  \n",
      "dem             0.000000        0.000000    0.000000      0.000000  \n",
      "pun             0.000177        0.000089    0.000089      0.000000  \n",
      "vb.pasthab.aut  0.000000        0.000000    0.000000      0.000000  \n",
      "obj             0.000000        0.000000    0.000000      0.000000  \n",
      "par             0.000000        0.000000    0.000363      0.000000  \n",
      "neg             0.000000        0.000000    0.003413      0.000000  \n",
      "vb.ord          0.000000        0.000000    0.000000      0.000000  \n",
      "END             0.000000        0.000000    0.000000      0.000000  \n",
      "num             0.000000        0.000000    0.000000      0.000000  \n",
      "vb.past         0.000000        0.000000    0.000000      0.000000  \n",
      "rel             0.000000        0.000000    0.001436      0.000000  \n",
      "vn              0.000000        0.000000    0.000000      0.000000  \n",
      "adv             0.000000        0.000000    0.000000      0.000000  \n",
      "vb.pasthab      0.000000        0.000000    0.000000      0.000000  \n",
      "pos             0.000000        0.000000    0.000000      0.000000  \n",
      "comp            0.000000        0.000000    0.000608      0.000608  \n",
      "vb.ord.syn      0.000000        0.000000    0.000000      0.000000  \n",
      "qual            0.000000        0.000000    0.000000      0.000000  \n",
      "vb.past.aut     0.003774        0.000000    0.000000      0.000000  \n",
      "vb.con          0.000000        0.000000    0.000000      0.000000  \n",
      "sub             0.000000        0.000000    0.000000      0.000000  \n",
      "vb.past.syn     0.000000        0.000000    0.000000      0.000000  \n",
      "vb.pres         0.000000        0.000000    0.000000      0.000000  \n",
      "sconj           0.000000        0.001992    0.004980      0.000000  \n",
      "vb.sub          0.000000        0.000000    0.000000      0.000000  \n",
      "eng             0.000000        0.000000    0.000000      0.000000  \n",
      "q               0.000000        0.000000    0.000000      0.000000  \n",
      "sym             0.000000        0.000000    0.000000      0.000000  \n",
      "vb.pres.syn     0.000000        0.000000    0.000000      0.000000  \n",
      "vb.fut          0.000000        0.000000    0.000000      0.000000  \n",
      "vb.con.aut      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.ord.aut      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.fut.aut      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.sub.aut      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.con.syn      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.pasthab.syn  0.000000        0.000000    0.000000      0.000000  \n",
      "int             0.000000        0.000000    0.000000      0.000000  \n",
      "voc             0.000000        0.000000    0.000000      0.000000  \n",
      "vb.pres.spec    0.000000        0.000000    0.000000      0.000000  \n",
      "vb.fut.spec     0.000000        0.000000    0.000000      0.000000  \n",
      "vb.preshab      0.000000        0.000000    0.000000      0.000000  \n",
      "abbr            0.000000        0.000000    0.000000      0.000000  \n",
      "vb.inf          0.000000        0.000000    0.000000      0.000000  \n",
      "vb.fut.syn      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.pres.aut     0.000000        0.000000    0.000000      0.000000  \n",
      "vb.preshab.aut  0.000000        0.000000    0.000000      0.000000  \n",
      "for             0.090909        0.000000    0.000000      0.000000  \n",
      "vb.preshab.syn  0.000000        0.000000    0.000000      0.000000  \n",
      "vb.sub.syn      0.000000        0.000000    0.000000      0.000000  \n",
      "vb.past.spec    0.000000        0.000000    0.000000      0.000000  \n",
      "\n",
      "[58 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "#### CREATE TABLE OF Transition probabilities for 1-grams ###\n",
    "# Create a dataframe with row indexes and column indexes both being the TAGS\n",
    "# Also iterate through and count how many times each TAG (row) is followed by other TAG\n",
    "\n",
    "# For row indexes, create list of tags used in the corpus\n",
    "row_indexes = []\n",
    "for sent in tuple_list:\n",
    "    for tup in sent:\n",
    "        if tup[1] not in row_indexes:\n",
    "            row_indexes.append(tup[1])\n",
    "\n",
    "#Create dict with a key for each column in the table, and all values set to zero\n",
    "empty_unigram_dict = {}\n",
    "for tag in row_indexes:\n",
    "    empty_unigram_dict[tag] = 0\n",
    "\n",
    "#Create a list of dicts, where each dict is one row of the table\n",
    "unigram_count = []\n",
    "for tag in row_indexes:\n",
    "    unigram_count.append(empty_unigram_dict.copy())\n",
    "    \n",
    "\n",
    "# Iterate through corpus to count frequency of each tag following each tag\n",
    "for n in range(len(row_indexes)):\n",
    "    for sent in tuple_list:\n",
    "        for i in range(len(sent)-1):\n",
    "            if sent[i][1] == row_indexes[n]:\n",
    "                unigram_count[n][sent[i+1][1]]+=1\n",
    "\n",
    "\n",
    "#Create copy of the table, then calculate averages by dividing each cell in row by the row_total\n",
    "unigram_data = []\n",
    "for item in unigram_count:\n",
    "    unigram_data.append(item)\n",
    "\n",
    "for n in range(len(unigram_count)):\n",
    "    row_total = 0\n",
    "    for key, value in unigram_count[n].items():\n",
    "        row_total+= value\n",
    "    if row_total!= 0:\n",
    "        for k, v in unigram_data[n].items():\n",
    "            unigram_data[n][k]=v/row_total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save data as dataframe\n",
    "unigrams_df = pandas.DataFrame(unigram_data, row_indexes)\n",
    "print(unigrams_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  START       cop       adj       det      noun      conj  \\\n",
      "START_cop           0.0  0.001931  0.320463  0.009653  0.310811  0.007722   \n",
      "cop_adj             0.0  0.026688  0.020408  0.056515  0.089482  0.015699   \n",
      "adj_adj             0.0  0.010638  0.063830  0.023404  0.068085  0.059574   \n",
      "adj_det             0.0  0.005208  0.010417  0.000000  0.864583  0.000000   \n",
      "det_noun            0.0  0.027675  0.115314  0.008764  0.083256  0.043589   \n",
      "...                 ...       ...       ...       ...       ...       ...   \n",
      "END_vb.past.aut     0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "dem_q               0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.ord.aut_par      0.0  0.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "prop_vb.past.aut    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pres.aut_rel     0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "                      prep      prop       dem       pun  ...  vb.preshab  \\\n",
      "START_cop         0.055985  0.000000  0.003861  0.013514  ...         0.0   \n",
      "cop_adj           0.287284  0.009419  0.014129  0.097331  ...         0.0   \n",
      "adj_adj           0.285106  0.006383  0.031915  0.212766  ...         0.0   \n",
      "adj_det           0.000000  0.088542  0.000000  0.000000  ...         0.0   \n",
      "det_noun          0.169742  0.061347  0.121310  0.154059  ...         0.0   \n",
      "...                    ...       ...       ...       ...  ...         ...   \n",
      "END_vb.past.aut   0.000000  1.000000  0.000000  0.000000  ...         0.0   \n",
      "dem_q             0.000000  0.000000  0.000000  0.000000  ...         0.0   \n",
      "vb.ord.aut_par    0.000000  0.000000  0.000000  0.000000  ...         0.0   \n",
      "prop_vb.past.aut  0.000000  0.000000  0.000000  0.000000  ...         0.0   \n",
      "vb.pres.aut_rel   0.000000  0.000000  0.000000  0.000000  ...         0.0   \n",
      "\n",
      "                  abbr    vb.inf  vb.fut.syn  vb.pres.aut  vb.preshab.aut  \\\n",
      "START_cop          0.0  0.000000         0.0          0.0             0.0   \n",
      "cop_adj            0.0  0.000000         0.0          0.0             0.0   \n",
      "adj_adj            0.0  0.000000         0.0          0.0             0.0   \n",
      "adj_det            0.0  0.000000         0.0          0.0             0.0   \n",
      "det_noun           0.0  0.000231         0.0          0.0             0.0   \n",
      "...                ...       ...         ...          ...             ...   \n",
      "END_vb.past.aut    0.0  0.000000         0.0          0.0             0.0   \n",
      "dem_q              0.0  0.000000         0.0          0.0             0.0   \n",
      "vb.ord.aut_par     0.0  0.000000         0.0          0.0             0.0   \n",
      "prop_vb.past.aut   0.0  0.000000         0.0          0.0             0.0   \n",
      "vb.pres.aut_rel    0.0  0.000000         0.0          0.0             0.0   \n",
      "\n",
      "                       for  vb.preshab.syn  vb.sub.syn  vb.past.spec  \n",
      "START_cop         0.000000             0.0         0.0           0.0  \n",
      "cop_adj           0.000000             0.0         0.0           0.0  \n",
      "adj_adj           0.000000             0.0         0.0           0.0  \n",
      "adj_det           0.000000             0.0         0.0           0.0  \n",
      "det_noun          0.000461             0.0         0.0           0.0  \n",
      "...                    ...             ...         ...           ...  \n",
      "END_vb.past.aut   0.000000             0.0         0.0           0.0  \n",
      "dem_q             0.000000             0.0         0.0           0.0  \n",
      "vb.ord.aut_par    0.000000             0.0         0.0           0.0  \n",
      "prop_vb.past.aut  0.000000             0.0         0.0           0.0  \n",
      "vb.pres.aut_rel   0.000000             0.0         0.0           0.0  \n",
      "\n",
      "[1316 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "#### CREATE TABLE OF Transition probabilities for 2-grams ###\n",
    "# Create a dataframe with row indexes being 2-grams of TAGS and column indexes being the following TAG\n",
    "# Iterate through and count how many times each 2-gram of TAGs (row) is followed by each other TAG\n",
    "\n",
    "\n",
    "bi_row_indexes = []\n",
    "for sent in tuple_list:\n",
    "    for i in range(len(sent)-1):\n",
    "        if (sent[i][1], sent[i+1][1]) not in bi_row_indexes:\n",
    "            bi_row_indexes.append((sent[i][1], sent[i+1][1]))\n",
    "\n",
    "# Create row index labels by contcatenating the tuples\n",
    "bi_row_indexes_concat = []\n",
    "for item in bi_row_indexes:\n",
    "    bi_row_indexes_concat.append(\"_\".join(item))\n",
    "\n",
    "\n",
    "\n",
    "#Create dict with a key for each column in the table, and all values set to zero\n",
    "empty_bigram_dict = {}\n",
    "for tag in row_indexes:\n",
    "    empty_bigram_dict[tag] = 0\n",
    "\n",
    "#Create a list of dicts, where each dict is one row of the table\n",
    "bigram_count = []\n",
    "for tag in bi_row_indexes_concat:\n",
    "    bigram_count.append(empty_bigram_dict.copy())\n",
    "    \n",
    "\n",
    "\n",
    "# Iterate through corpus to count frequency of each tag following each tag\n",
    "for n in range(len(bi_row_indexes_concat)):\n",
    "    for sent in tuple_list:\n",
    "        for i in range(len(sent)-2):\n",
    "            if \"_\".join((sent[i][1], sent[i+1][1])) == bi_row_indexes_concat[n]:\n",
    "                bigram_count[n][sent[i+2][1]]+=1\n",
    "    \n",
    "#Create copy of the table, then calculate averages by dividing each cell in row by the row_total\n",
    "bigram_data = []\n",
    "for item in bigram_count:\n",
    "    bigram_data.append(item)\n",
    "\n",
    "for n in range(len(bigram_count)):\n",
    "    bi_row_total = 0\n",
    "    for key, value in bigram_count[n].items():\n",
    "        bi_row_total+= value\n",
    "    if bi_row_total!= 0:\n",
    "        for k, v in bigram_data[n].items():\n",
    "            bigram_data[n][k]=v/bi_row_total\n",
    "\n",
    "\n",
    "# Save data as dataframe\n",
    "bigrams_df = pandas.DataFrame(bigram_data, bi_row_indexes_concat)\n",
    "print(bigrams_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN CSV FILE FOR EMISSION PROBABILITIES\n",
    "df2 = pandas.read_csv('trainingset_emissions.csv')\n",
    "single_str_list2 = df2.values.tolist()\n",
    "\n",
    "table2 = []\n",
    "for sent in single_str_list2:\n",
    "    table2.append(sent[1:])\n",
    "\n",
    "\n",
    "#Split tags back into list of lists (sentences) of tuples:\n",
    "tuple_list2 = []\n",
    "for sent in table2:\n",
    "    new_sent = []\n",
    "    for tag_pair in sent:\n",
    "        tag_pair = str(tag_pair)\n",
    "        for i in range(len(tag_pair)):\n",
    "            if tag_pair[i] == '_':\n",
    "                new_sent.append((tag_pair[:i], tag_pair[i+1:]))\n",
    "    tuple_list2.append(new_sent)\n",
    "\n",
    "print(tuple_list2[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                <START>        Ba      mhór     uilig        an  t-éagóir  \\\n",
      "START               1.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "cop                 0.0  0.075128  0.000000  0.000000  0.000000  0.000000   \n",
      "adj                 0.0  0.000000  0.008401  0.001777  0.000000  0.000000   \n",
      "det                 0.0  0.000000  0.000000  0.000000  0.675023  0.000000   \n",
      "noun                0.0  0.000000  0.000000  0.000000  0.003491  0.000041   \n",
      "conj                0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "prep                0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "prop                0.0  0.000000  0.000000  0.000000  0.001993  0.000000   \n",
      "dem                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "pun                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pasthab.aut      0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "obj                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "par                 0.0  0.000000  0.000000  0.000000  0.288978  0.000000   \n",
      "neg                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.ord              0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "END                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "num                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.past             0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rel                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vn                  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "adv                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pasthab          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "pos                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "comp                0.0  0.001824  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.ord.syn          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "qual                0.0  0.000000  0.000000  0.013477  0.000000  0.000000   \n",
      "vb.past.aut         0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.con              0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "sub                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.past.syn         0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pres             0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "sconj               0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.sub              0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "eng                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "q                   0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "sym                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pres.syn         0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.fut              0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.con.aut          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.ord.aut          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.fut.aut          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.sub.aut          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.con.syn          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pasthab.syn      0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "int                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "voc                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pres.spec        0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.fut.spec         0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.preshab          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "abbr                0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.inf              0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.fut.syn          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.pres.aut         0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.preshab.aut      0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "for                 0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.preshab.syn      0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.sub.syn          0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "vb.past.spec        0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "                    agus   leatrom        ar    fheara  ...  nuálaíochta  \\\n",
      "START           0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "cop             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "adj             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "det             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "noun            0.014130  0.000123  0.000000  0.000041  ...     0.000041   \n",
      "conj            0.496557  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "prep            0.000000  0.000000  0.147738  0.000000  ...     0.000000   \n",
      "prop            0.000000  0.000000  0.000111  0.000000  ...     0.000000   \n",
      "dem             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "pun             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pasthab.aut  0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "obj             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "par             0.000000  0.000000  0.031907  0.000000  ...     0.000000   \n",
      "neg             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.ord          0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "END             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "num             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.past         0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "rel             0.000000  0.000000  0.017801  0.000000  ...     0.000000   \n",
      "vn              0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "adv             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pasthab      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "pos             0.000000  0.000000  0.043946  0.000000  ...     0.000000   \n",
      "comp            0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.ord.syn      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "qual            0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.past.aut     0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.con          0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "sub             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.past.syn     0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pres         0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "sconj           0.232072  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.sub          0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "eng             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "q               0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "sym             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pres.syn     0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.fut          0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.con.aut      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.ord.aut      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.fut.aut      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.sub.aut      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.con.syn      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pasthab.syn  0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "int             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "voc             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pres.spec    0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.fut.spec     0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.preshab      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "abbr            0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.inf          0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.fut.syn      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.pres.aut     0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.preshab.aut  0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "for             0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.preshab.syn  0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.sub.syn      0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "vb.past.spec    0.000000  0.000000  0.000000  0.000000  ...     0.000000   \n",
      "\n",
      "                   muirí  heicteár     'Cuan  Cliabháin    Bradán    tuilte  \\\n",
      "START           0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "cop             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "adj             0.000000  0.000000  0.000000   0.000000  0.000000  0.000162   \n",
      "det             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "noun            0.000041  0.000000  0.000041   0.000000  0.000000  0.000000   \n",
      "conj            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "prep            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "prop            0.000000  0.000000  0.000000   0.000111  0.000111  0.000000   \n",
      "dem             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "pun             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pasthab.aut  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "obj             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "par             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "neg             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.ord          0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "END             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "num             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.past         0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "rel             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vn              0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "adv             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pasthab      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "pos             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "comp            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.ord.syn      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "qual            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.past.aut     0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.con          0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "sub             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.past.syn     0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pres         0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "sconj           0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.sub          0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "eng             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "q               0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "sym             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pres.syn     0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.fut          0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.con.aut      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.ord.aut      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.fut.aut      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.sub.aut      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.con.syn      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pasthab.syn  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "int             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "voc             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pres.spec    0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.fut.spec     0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.preshab      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "abbr            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.inf          0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.fut.syn      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.pres.aut     0.000000  0.009901  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.preshab.aut  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "for             0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.preshab.syn  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.sub.syn      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "vb.past.spec    0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "\n",
      "                   chuan  Limistéar  Chaomhnú  \n",
      "START           0.000000   0.000000  0.000000  \n",
      "cop             0.000000   0.000000  0.000000  \n",
      "adj             0.000000   0.000000  0.000000  \n",
      "det             0.000000   0.000000  0.000000  \n",
      "noun            0.000041   0.000000  0.000000  \n",
      "conj            0.000000   0.000000  0.000000  \n",
      "prep            0.000000   0.000000  0.000000  \n",
      "prop            0.000000   0.000111  0.000000  \n",
      "dem             0.000000   0.000000  0.000000  \n",
      "pun             0.000000   0.000000  0.000000  \n",
      "vb.pasthab.aut  0.000000   0.000000  0.000000  \n",
      "obj             0.000000   0.000000  0.000000  \n",
      "par             0.000000   0.000000  0.000000  \n",
      "neg             0.000000   0.000000  0.000000  \n",
      "vb.ord          0.000000   0.000000  0.000000  \n",
      "END             0.000000   0.000000  0.000000  \n",
      "num             0.000000   0.000000  0.000000  \n",
      "vb.past         0.000000   0.000000  0.000000  \n",
      "rel             0.000000   0.000000  0.000000  \n",
      "vn              0.000000   0.000000  0.000281  \n",
      "adv             0.000000   0.000000  0.000000  \n",
      "vb.pasthab      0.000000   0.000000  0.000000  \n",
      "pos             0.000000   0.000000  0.000000  \n",
      "comp            0.000000   0.000000  0.000000  \n",
      "vb.ord.syn      0.000000   0.000000  0.000000  \n",
      "qual            0.000000   0.000000  0.000000  \n",
      "vb.past.aut     0.000000   0.000000  0.000000  \n",
      "vb.con          0.000000   0.000000  0.000000  \n",
      "sub             0.000000   0.000000  0.000000  \n",
      "vb.past.syn     0.000000   0.000000  0.000000  \n",
      "vb.pres         0.000000   0.000000  0.000000  \n",
      "sconj           0.000000   0.000000  0.000000  \n",
      "vb.sub          0.000000   0.000000  0.000000  \n",
      "eng             0.000000   0.000000  0.000000  \n",
      "q               0.000000   0.000000  0.000000  \n",
      "sym             0.000000   0.000000  0.000000  \n",
      "vb.pres.syn     0.000000   0.000000  0.000000  \n",
      "vb.fut          0.000000   0.000000  0.000000  \n",
      "vb.con.aut      0.000000   0.000000  0.000000  \n",
      "vb.ord.aut      0.000000   0.000000  0.000000  \n",
      "vb.fut.aut      0.000000   0.000000  0.000000  \n",
      "vb.sub.aut      0.000000   0.000000  0.000000  \n",
      "vb.con.syn      0.000000   0.000000  0.000000  \n",
      "vb.pasthab.syn  0.000000   0.000000  0.000000  \n",
      "int             0.000000   0.000000  0.000000  \n",
      "voc             0.000000   0.000000  0.000000  \n",
      "vb.pres.spec    0.000000   0.000000  0.000000  \n",
      "vb.fut.spec     0.000000   0.000000  0.000000  \n",
      "vb.preshab      0.000000   0.000000  0.000000  \n",
      "abbr            0.000000   0.000000  0.000000  \n",
      "vb.inf          0.000000   0.000000  0.000000  \n",
      "vb.fut.syn      0.000000   0.000000  0.000000  \n",
      "vb.pres.aut     0.000000   0.000000  0.000000  \n",
      "vb.preshab.aut  0.000000   0.000000  0.000000  \n",
      "for             0.000000   0.000000  0.000000  \n",
      "vb.preshab.syn  0.000000   0.000000  0.000000  \n",
      "vb.sub.syn      0.000000   0.000000  0.000000  \n",
      "vb.past.spec    0.000000   0.000000  0.000000  \n",
      "\n",
      "[58 rows x 15074 columns]\n"
     ]
    }
   ],
   "source": [
    "#### CREATE TABLE OF emission probabilities ###\n",
    "\n",
    "# Create a list of all tokens in corpus\n",
    "tokens_list = []\n",
    "for sent in tuple_list2:\n",
    "    for tup in sent:\n",
    "        if tup[0] not in tokens_list:\n",
    "            tokens_list.append(tup[0])\n",
    "\n",
    "\n",
    "\n",
    "#Create dict with a key for each column in the table, and all values set to zero\n",
    "empty_token_dict = {}\n",
    "for tok in tokens_list:\n",
    "    empty_token_dict[tok] = 0\n",
    "\n",
    "#Create a list of dicts, where each dict is one row of the table\n",
    "token_count = []\n",
    "for tag in row_indexes:\n",
    "    token_count.append(empty_token_dict.copy())\n",
    "    \n",
    "\n",
    "\n",
    "# Iterate through corpus to count frequency of each token assigned as each tag\n",
    "for n in range(len(row_indexes)):\n",
    "    for sent in tuple_list:\n",
    "        for i in range(len(sent)):\n",
    "            if sent[i][1] == row_indexes[n]:\n",
    "                token_count[n][sent[i][0]]+=1\n",
    "    \n",
    "    \n",
    "#Create copy of the table, then calculate averages by dividing each cell in row by the row_total\n",
    "emission_data = []\n",
    "for item in token_count:\n",
    "    emission_data.append(item)\n",
    "\n",
    "for n in range(len(token_count)):\n",
    "    row_total = 0\n",
    "    for key, value in token_count[n].items():\n",
    "        row_total+= value\n",
    "    if row_total!= 0:\n",
    "        for k, v in emission_data[n].items():\n",
    "            emission_data[n][k]=v/row_total\n",
    "\n",
    "\n",
    "# Save data as dataframe\n",
    "emission_df = pandas.DataFrame(emission_data, row_indexes)\n",
    "print(emission_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TESTSET TO TAG\n",
    "df3 = pandas.read_csv('testset.csv')\n",
    "single_str_list3 = df3.values.tolist()\n",
    "\n",
    "index_removed = []\n",
    "for sent in single_str_list3:\n",
    "    index_removed.append(sent[1:])\n",
    "\n",
    "test_dataset = []\n",
    "for sent in index_removed:\n",
    "    new_sent = []\n",
    "    for i in range(len(sent)):\n",
    "        if sent[i] == '<END>':\n",
    "            test_dataset.append(sent[:i+1])\n",
    "\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Viterbi algorithm for uni-grams\n",
    "\n",
    "\n",
    "# First find the possible tags for each token with their non-zero emission probability\n",
    "tagged_sents_unigrams_tuples = []\n",
    "for sent in test_dataset:\n",
    "    # Initialise value start tag\n",
    "    pathway_values = {'START':1.0}\n",
    "    pathway_labels = {'START':'START'}\n",
    "    for n in range(len(sent)-1):\n",
    "        poss_token_tags = {}\n",
    "        # Resolve OOV tokens\n",
    "        if sent[n+1] not in emission_df.columns:\n",
    "            # Assume capitalised words are proper nouns\n",
    "            if len(sent[n+1]) > 1 and ((n > 0 and sent[n+1].isalpha() and sent[n+1][0].isupper() and len(sent[n+1]) > 1) or (n > 0 and sent[n+1].isalpha() and sent[n+1][1].isupper() and len(sent[n+1]) > 1)):\n",
    "                poss_token_tags = {'prop':1.0}\n",
    "            # Otherwise, use the top three transmission probabilities from the previous token to define placeholder tags\n",
    "            else:\n",
    "                for m in pathway_values.keys():\n",
    "                    values_top3_trans = unigrams_df.loc[m].nlargest(3).values.tolist()\n",
    "                    index_top3_trans = unigrams_df.loc[m].nlargest(3).index.values.tolist()\n",
    "                    for k in range(len(values_top3_trans)):\n",
    "                        # Exclude any zero-probabilties\n",
    "                        if values_top3_trans[k] != 0.0:\n",
    "                            # Add tags and their highest probabilities to dictionary for current token\n",
    "                            if index_top3_trans[k] not in poss_token_tags.keys():\n",
    "                                poss_token_tags[index_top3_trans[k]] = values_top3_trans[k]*pathway_values[m]\n",
    "                            elif values_top3_trans[k] > poss_token_tags[index_top3_trans[k]]:\n",
    "                                poss_token_tags[index_top3_trans[k]] = values_top3_trans[k]*pathway_values[m]\n",
    "                        else:\n",
    "                            poss_token_tags = {'for':1.0}\n",
    "        else:\n",
    "            # For each known token, find emmision probaility from table\n",
    "            tag_index = emission_df[sent[n+1]].index.values.tolist()\n",
    "            tag_column = emission_df[sent[n+1]].values.tolist()\n",
    "            for t in range(len(tag_index)):\n",
    "                # Exclude emmissions with zero-probability\n",
    "                if tag_column[t]>0:\n",
    "                    for m in pathway_values.keys():\n",
    "                        if tag_index[t] not in poss_token_tags.keys():\n",
    "                            poss_token_tags[tag_index[t]] = tag_column[t]\n",
    "                        elif tag_column[t] > poss_token_tags[tag_index[t]]:\n",
    "                            poss_token_tags[tag_index[t]] = tag_column[t]\n",
    "        # Update the dictionary of the most probable tag pathways\n",
    "        temp_pathway_values = {}\n",
    "        temp_pathway_labels = {}   \n",
    "        for j in poss_token_tags.keys():\n",
    "            highest_path_to_j = 0\n",
    "            label_of_jtoken = ''\n",
    "            for i in pathway_values.keys():\n",
    "                if unigrams_df.at[i,j] > 0.0:\n",
    "                    if len(sent) > 20:\n",
    "                        current_path = pathway_values[i]*unigrams_df.at[i,j]*poss_token_tags[j]*1000\n",
    "                    else:\n",
    "                        current_path = pathway_values[i]*unigrams_df.at[i,j]*poss_token_tags[j]*10\n",
    "                    if current_path > highest_path_to_j:\n",
    "                        highest_path_to_j = current_path\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[j] = highest_path_to_j\n",
    "                elif not unigrams_df.at[i,j] and len(poss_token_tags) == 1:\n",
    "                    if len(sent) > 20:\n",
    "                        highest_path_to_j = pathway_values[i]*poss_token_tags[j]*1000\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[j] = highest_path_to_j\n",
    "                    else:\n",
    "                        highest_path_to_j = pathway_values[i]*poss_token_tags[j]*10\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[j] = highest_path_to_j\n",
    "        # Update the dictionary of the most probable tag pathways\n",
    "        pathway_values = temp_pathway_values\n",
    "        pathway_labels = temp_pathway_labels\n",
    "    # Append the final most probable tag pathway to the list of sentences\n",
    "    final_tag_list = []\n",
    "    tagged_sentence = []\n",
    "    for v in pathway_labels.values():\n",
    "        marker = -1\n",
    "        for i in range(len(v)):\n",
    "            marker+=1\n",
    "            if v[i] == '_':\n",
    "                final_tag_list.append(v[i-marker:i])\n",
    "                marker = -1\n",
    "        final_tag_list.append(v[i-marker:])\n",
    "        for n in range(len(sent)):\n",
    "            tagged_sentence.append((sent[n], final_tag_list[n]))\n",
    "    tagged_sents_unigrams_tuples.append(tagged_sentence)\n",
    "\n",
    "\n",
    "\n",
    "print(len(tagged_sents_unigrams_tuples), 'sentences tagged with unigrams.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Viterbi algorithm for bi-grams\n",
    "\n",
    "    \n",
    "# First find the possible tags for each token with their non-zero emission probability\n",
    "tagged_sents_bigrams_tuples = []\n",
    "for sent in test_dataset:\n",
    "###########################################################################\n",
    "#RUN THE UNIGRAM MODEL FIRST TO GET PATHWAY FOR FIRST TWO TAGS\n",
    "    # Initialise value start tag\n",
    "    count = 0\n",
    "    pathway_values = {'START':1.0}\n",
    "    pathway_labels = {'START':'START'}\n",
    "    for n in range(1):\n",
    "        poss_token_tags = {}\n",
    "        # Resolve OOV tokens\n",
    "        if sent[n+1] not in emission_df.columns:\n",
    "            # Assume capitalised words are proper nouns\n",
    "            if len(sent[n+1]) > 1 and ((n > 0 and sent[n+1].isalpha() and sent[n+1][0].isupper() and len(sent[n+1]) > 1) or (n > 0 and sent[n+1].isalpha() and sent[n+1][1].isupper() and len(sent[n+1]) > 1)):\n",
    "                poss_token_tags = {'prop':1.0}\n",
    "            # Otherwise, use the top three transmission probabilities from the previous token to define placeholder tags\n",
    "            else:\n",
    "                for m in pathway_values.keys():\n",
    "                    # Find the three top values of unigram transmissions from table and their indices for each possible tag of the previous token\n",
    "                    values_top3_trans = unigrams_df.loc[m].nlargest(3).values.tolist()\n",
    "                    index_top3_trans = unigrams_df.loc[m].nlargest(3).index.values.tolist()\n",
    "                    for k in range(len(values_top3_trans)):\n",
    "                        # Exclude any zero-probabilties\n",
    "                        if values_top3_trans[k] != 0.0:\n",
    "                            # Add tags and their highest probabilities to dictionary for current token\n",
    "                            if index_top3_trans[k] not in poss_token_tags.keys():\n",
    "                                poss_token_tags[index_top3_trans[k]] = values_top3_trans[k]*pathway_values[m]\n",
    "                            elif values_top3_trans[k] > poss_token_tags[index_top3_trans[k]]:\n",
    "                                poss_token_tags[index_top3_trans[k]] = values_top3_trans[k]*pathway_values[m]\n",
    "                        else:\n",
    "                            poss_token_tags = {'for':1.0}\n",
    "        else:\n",
    "            # For each known token, find emmision probaility from table\n",
    "            tag_index = emission_df[sent[n+1]].index.values.tolist()\n",
    "            tag_column = emission_df[sent[n+1]].values.tolist()\n",
    "            for t in range(len(tag_index)):\n",
    "                # Exclude emmissions with zero-probability\n",
    "                if tag_column[t]>0:\n",
    "                    for m in pathway_values.keys():\n",
    "                        if tag_index[t] not in poss_token_tags.keys():\n",
    "                            poss_token_tags[tag_index[t]] = tag_column[t]\n",
    "                        elif tag_column[t] > poss_token_tags[tag_index[t]]:\n",
    "                            poss_token_tags[tag_index[t]] = tag_column[t]\n",
    "        # Find the most probable pathway to each node\n",
    "        temp_pathway_values = {}\n",
    "        temp_pathway_labels = {}   \n",
    "        for j in poss_token_tags.keys():\n",
    "            highest_path_to_j = 0\n",
    "            label_of_jtoken = ''\n",
    "            for i in pathway_values.keys():\n",
    "                if unigrams_df.at[i,j] > 0.0:# Find the most probable pathway to each node\n",
    "                    current_path = pathway_values[i]*unigrams_df.at[i,j]*poss_token_tags[j]\n",
    "                    if current_path > highest_path_to_j:\n",
    "                        highest_path_to_j = current_path\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[j] = highest_path_to_j\n",
    "                elif not unigrams_df.at[i,j] and len(poss_token_tags) == 1:\n",
    "                    highest_path_to_j = pathway_values[i]*poss_token_tags[j]\n",
    "                    label_of_jtoken = '_'+j\n",
    "                    temp_pathway_labels[j] = pathway_labels[i]+label_of_jtoken\n",
    "                    temp_pathway_values[j] = highest_path_to_j\n",
    "        pathway_values = temp_pathway_values\n",
    "        pathway_labels = temp_pathway_labels\n",
    "        count+=1\n",
    "    if count == 1:\n",
    "        pathway_values['START'+'_'+max(pathway_labels)] = 1.0\n",
    "        pathway_labels['START'+'_'+max(pathway_labels)] = 'START'+'_'+max(pathway_labels)\n",
    "################################################################################\n",
    "    # PART II: BIGRAM MODEL FOR TOKENS n+3 ONWARDS\n",
    "    for n in range(len(sent)-2):\n",
    "        poss_token_tags = {}\n",
    "        # Resolve OOV tokens\n",
    "        if sent[n+2] not in emission_df.columns:\n",
    "            # Assume capitalised words are proper nouns\n",
    "            if len(sent[n+2]) > 1 and (n > 0 and sent[n+2].isalpha() and sent[n+2][0].isupper() and len(sent[n+2]) > 1 or n > 0 and sent[n+2].isalpha() and sent[n+2][1].isupper() and len(sent[n+2]) > 1):\n",
    "                poss_token_tags = {'prop':1.0}\n",
    "            # If not proper noun, use the top three transmission probabilities from the previous token to define placeholder tags\n",
    "            else:\n",
    "                for m in pathway_values.keys():\n",
    "                    if m in bigrams_df.index:\n",
    "                        # Find the three top values of unigram transmissions from table and their indices for each possible tag of the previous token\n",
    "                        values_top3_trans = bigrams_df.loc[m].nlargest(3).values.tolist()\n",
    "                        index_top3_trans = bigrams_df.loc[m].nlargest(3).index.values.tolist()\n",
    "                        for k in range(len(values_top3_trans)):\n",
    "                            # Exclude any zero-probabilties\n",
    "                            if values_top3_trans[k] != 0.0:\n",
    "                                # Add tags and their highest probabilities to dictionary for current token\n",
    "                                if index_top3_trans[k] not in poss_token_tags.keys():\n",
    "                                    poss_token_tags[index_top3_trans[k]] = values_top3_trans[k]*pathway_values[m]\n",
    "                                elif values_top3_trans[k] > poss_token_tags[index_top3_trans[k]]:\n",
    "                                    poss_token_tags[index_top3_trans[k]] = values_top3_trans[k]*pathway_values[m]\n",
    "                            else:\n",
    "                                poss_token_tags = {'for':1.0}\n",
    "                    else:\n",
    "                        for c in row_indexes:\n",
    "                            poss_token_tags[c] = float(1/len(row_indexes))\n",
    "        else:\n",
    "            # For each known token, find emmision probaility from table\n",
    "            tag_index = emission_df[sent[n+2]].index.values.tolist()\n",
    "            tag_column = emission_df[sent[n+2]].values.tolist()\n",
    "            for t in range(len(tag_index)):\n",
    "                # Exclude emmissions with zero-probability\n",
    "                if tag_column[t]>0:\n",
    "                    for m in pathway_values.keys():\n",
    "                        if tag_index[t] not in poss_token_tags.keys():\n",
    "                            poss_token_tags[tag_index[t]] = tag_column[t]\n",
    "                        elif tag_column[t] > poss_token_tags[tag_index[t]]:\n",
    "                            poss_token_tags[tag_index[t]] = tag_column[t]\n",
    "        # Update the dictionary of the most probable tag pathways\n",
    "        temp_pathway_values = {}\n",
    "        temp_pathway_labels = {}   \n",
    "        for j in poss_token_tags.keys():\n",
    "            highest_path_to_j = 0\n",
    "            label_of_jtoken = ''\n",
    "            for i in pathway_values.keys():\n",
    "                old_i = ''\n",
    "                for letter_num in range(len(i)):\n",
    "                    if i[letter_num] == '_':\n",
    "                        old_i = i[letter_num+1:]\n",
    "                if i in bigrams_df.index and bigrams_df.at[i,j] > 0.0:\n",
    "                    if len(sent) > 20:\n",
    "                        current_path = pathway_values[i]*bigrams_df.at[i,j]*poss_token_tags[j]*1000\n",
    "                    else:\n",
    "                        current_path = pathway_values[i]*bigrams_df.at[i,j]*poss_token_tags[j]*10\n",
    "                    if current_path > highest_path_to_j:\n",
    "                        highest_path_to_j = current_path\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[old_i+'_'+j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[old_i+'_'+j] = highest_path_to_j\n",
    "                elif i in bigrams_df.index and bigrams_df.at[i,j] == 0.0 and len(poss_token_tags) == 1:\n",
    "                    if len(sent) > 20:\n",
    "                        highest_path_to_j = pathway_values[i]*poss_token_tags[j]*1000\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[old_i+'_'+j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[old_i+'_'+j] = highest_path_to_j\n",
    "                    else:\n",
    "                        highest_path_to_j = pathway_values[i]*poss_token_tags[j]*10\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[old_i+'_'+j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[old_i+'_'+j] = highest_path_to_j\n",
    "                else:\n",
    "                    if len(sent) > 20:\n",
    "                        highest_path_to_j = pathway_values[i]*poss_token_tags[j]*1000\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[old_i+'_'+j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[old_i+'_'+j] = highest_path_to_j\n",
    "                    else:\n",
    "                        highest_path_to_j = pathway_values[i]*poss_token_tags[j]*10\n",
    "                        label_of_jtoken = '_'+j\n",
    "                        temp_pathway_labels[old_i+'_'+j] = pathway_labels[i]+label_of_jtoken\n",
    "                        temp_pathway_values[old_i+'_'+j] = highest_path_to_j\n",
    "        pathway_values = temp_pathway_values\n",
    "        pathway_labels = temp_pathway_labels\n",
    "    results = {}\n",
    "    for r in pathway_values.keys():\n",
    "        results[pathway_labels[r]] = pathway_values[r]\n",
    "    if len(results) > 0:\n",
    "        max_results = max(results)\n",
    "        final_tag_list = []\n",
    "        tagged_sentence = []\n",
    "        marker = -1\n",
    "        for i in range(len(max_results)):\n",
    "            marker+=1\n",
    "            if max_results[i] == '_':\n",
    "                final_tag_list.append(max_results[i-marker:i])\n",
    "                marker = -1\n",
    "        final_tag_list.append(max_results[i-marker:])\n",
    "        for n in range(len(sent)):\n",
    "            tagged_sentence.append((sent[n], final_tag_list[n]))\n",
    "        tagged_sents_bigrams_tuples.append(tagged_sentence)\n",
    "\n",
    "\n",
    "print(len(tagged_sents_bigrams_tuples), 'sentences tagged with bigrams.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVERT TUPLES TO LIST OF STRINGS AND SAVE AS CSV\n",
    "\n",
    "#WRITING LIST TO CSV FILE\n",
    "new_list = []\n",
    "for sent in tagged_sents_unigrams_tuples:\n",
    "    new_sent = []\n",
    "    for tup in sent:\n",
    "        new_sent.append(\"_\".join(tup))\n",
    "    new_list.append(new_sent)\n",
    "pd = pandas.DataFrame(new_list)\n",
    "pd.to_csv(\"testset_tagged_with_unigrams.csv\")\n",
    "\n",
    "\n",
    "new_list = []\n",
    "for sent in tagged_sents_bigrams_tuples:\n",
    "    new_sent = []\n",
    "    for tup in sent:\n",
    "        new_sent.append(\"_\".join(tup))\n",
    "    new_list.append(new_sent)\n",
    "pd = pandas.DataFrame(new_list)\n",
    "pd.to_csv(\"testset_tagged_with_bigrams.csv\")\n",
    "\n",
    "print('Files saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
